{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are, too, lost with your SlackChannel messages and things get too complicated or you kept posting things and you literally lost track, this post can help you.\n",
    "\n",
    "As you may know, you can export your data on Slack. They send you a nice zip file where eack chanell is in their respective folders. And in each folder, you have day by day channel data in json format. Well if you do not know what you are doing, looking at those files can be even more intimidating. \n",
    "\n",
    "So my goal here is to make this process easy for you. Slack says take those files to your enginnering team, well I do not have one :) so  I made this for myself as I kept posting things and now I am lost and I really need all the links I posted to my channel.\n",
    "\n",
    "So here I will show you how to read all the json files at one time,then pull the entries with links on them then printing those links into a csv file. So at the end, you can go through all your Slack history and get all the links you have. \n",
    "\n",
    "I am sure, there are other ways and better ways to do this but this is what I have so far ;) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, json\n",
    "import re\n",
    "import csv\n",
    "\n",
    "\n",
    "path_to_json = '/Users/aybuke/Downloads/Educational Data Mining Slack export Jun 14 2017/general'\n",
    "json_files = [pos_json for pos_json in os.listdir(path_to_json)]\n",
    "\n",
    "#the content with link in it\n",
    "page = []\n",
    "for js in json_files:\n",
    "    with open(os.path.join(path_to_json, js)) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        for element in data:\n",
    "            Npage = element['text'] #I want the key value for the text key in the dictionary\n",
    "            page.append(Npage)\n",
    "\n",
    "#links\n",
    "Link = []\n",
    "def lookup(index,keyword):\n",
    "    for entry in index:\n",
    "        if keyword in entry:\n",
    "            regex = r'https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+'\n",
    "            match = re.search(regex, entry)\n",
    "            Link.append(match.group())\n",
    "    return []\n",
    "\n",
    "\n",
    "lookup(page,'<https://')\n",
    "#print Link --> this is just to make sure it is working \n",
    "\n",
    "#write the links to csv\n",
    "with open('mySlackChannel.csv', 'w', ) as myfile:\n",
    "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "    for element in Link:\n",
    "        wr.writerow([element]) #this is to write row by row\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
